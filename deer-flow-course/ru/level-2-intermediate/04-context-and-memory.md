---
title: "Контекст и память"
weight: 4
bookToc: true
---

# Контекст и память

## Введение

Большинство чат-ботов забывают всё, когда вы закрываете окно. DeerFlow — нет. У него есть два механизма сохранения информации: **управление контекстом** (в рамках сессии) и **долговременная память** (между сессиями).

## Контекст (внутри сессии)

### Что такое контекст?

**Контекст** — это вся информация, которую ИИ «видит» при обработке вашего сообщения. Сюда входят: системный промпт, история сообщений, данные о файлах, результаты работы инструментов.

### Проблема контекстного окна

У каждой ИИ-модели есть ограничение на количество текста — **контекстное окно**. Например, 128 000 токенов (~96 000 слов). Если разговор становится слишком длинным, старые сообщения «выпадают».

### Как DeerFlow решает эту проблему

#### 1. Изолированный контекст суб-агентов

Каждый суб-агент работает в **собственном контексте** и не видит контекст главного агента или других суб-агентов. Это экономит место в контекстном окне.

#### 2. Суммаризация (Summarization)

Когда контекст приближается к пределу, DeerFlow автоматически **сжимает** старые сообщения в краткое резюме.

Настройка в `config.yaml`:

```yaml
summarization:
  enabled: true
  trigger:
    type: tokens        # По количеству токенов
    threshold: 100000   # Порог срабатывания
  keep:
    recent_messages: 10  # Сколько последних сообщений оставить
```

#### 3. Выгрузка в файловую систему

Промежуточные результаты суб-агентов сохраняются в файлы, а не хранятся в контексте. Это значительно экономит место.

## Долговременная память (между сессиями)

### Как работает память

DeerFlow **автоматически извлекает** важную информацию из ваших разговоров и сохраняет её. При следующем разговоре эта информация включается в системный промпт.

### Что запоминается

Память хранится в файле `memory.json` и содержит:

```json
{
  "userContext": {
    "workContext": "Работает фронтенд-разработчиком",
    "personalContext": "Предпочитает TypeScript",
    "topOfMind": "Сейчас изучает Rust"
  },
  "history": {
    "recentMonths": "...",
    "earlierContext": "...",
    "longTermBackground": "..."
  },
  "facts": [
    {
      "id": "fact-1",
      "content": "Предпочитает тёмную тему в IDE",
      "category": "preference",
      "confidence": 0.9
    }
  ]
}
```

### Категории фактов

| Категория | Описание | Пример |
|-----------|----------|--------|
| `preference` | Предпочтения | «Любит краткие ответы» |
| `knowledge` | Знания | «Знает Python и JavaScript» |
| `context` | Контекст | «Работает в стартапе» |
| `behavior` | Поведение | «Часто просит примеры кода» |
| `goal` | Цели | «Хочет выучить Go» |

### Настройка памяти

```yaml
# config.yaml
memory:
  enabled: true                  # Включить память
  injection_enabled: true        # Вставлять память в промпт
  storage_path: .deer-flow/memory.json
  debounce_seconds: 30           # Задержка перед обновлением
  max_facts: 100                 # Максимум фактов
  fact_confidence_threshold: 0.7 # Минимальная уверенность
  max_injection_tokens: 2000     # Лимит токенов для инъекции
```

### Как обновляется память

1. Вы общаетесь с DeerFlow
2. **MemoryMiddleware** отбирает важные сообщения
3. Через 30 секунд (debounce) запускается анализ
4. ИИ извлекает факты и контекст
5. Обновляет `memory.json` атомарно (безопасно)
6. При следующем запросе — информация уже в промпте

### Управление памятью через API

- `GET /api/memory` — посмотреть текущую память
- `POST /api/memory/reload` — перезагрузить
- `GET /api/memory/status` — статус системы памяти

## Практический пример

Попробуйте:

```
Сессия 1: "Привет! Я работаю Data Scientist, использую Python и pandas."
Сессия 2: "Помоги мне с анализом данных."
```

Во второй сессии DeerFlow уже будет знать, что вы Data Scientist, и предложит решение на Python с pandas.

## Итоги

- Контекст управляется через изоляцию суб-агентов и суммаризацию
- Долговременная память сохраняет факты, предпочтения и контекст
- Память обновляется автоматически в фоновом режиме
- Хранится локально в `memory.json` под вашим контролем
- Можно настроить через `config.yaml` и управлять через API
